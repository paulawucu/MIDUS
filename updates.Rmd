---
title: "Updates"
author: "Paula Wu"
date: "4/20/2022"
output: github_document
---

### Apr.20 Updates
1. Get rid of the outliers in `B3TCOMPZ3`,`B3TEMZ3`, `B3TEFZ3` and re-draw the graphs. 
2. M3 family number investigation and imputation. Integrate the milwaukee sample data to the working datasets. 
3. For M2, only focus on subjects that has CTQ numbers. Integrate the milwaukee sample data to the working datasets. 
4. Recode for marital status (1 - married; 0 - other status)
5. Correlation Plot

### Apr.28 Updates
1. Stroke: report inconsistency - done
2. Covariates investigations - partially done. I'm still working on how to visualize the categorical independent variales against CTQ values
3. Resilience Factor - done
4. Missing Data proportion - small dataset done before, full dataset? Not sure..
5. Smoking - done
6. Remove invalid entries - done

### May.5 Updates
1. Missing data proportion - not done yet!
2. Stroke inconsistency double-check (M2 and M3)
3. Smoking inconsistency check and data imputation
4. (All) Resilience Factors and missing entries
5. 

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(patchwork)
library(caret)
library(GGally)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)
theme_set(theme_minimal() + theme(legend.position = "bottom") + theme(plot.title = element_text(hjust = 0.5)))
```

```{r, echo=FALSE}
# reading datas
m2p3 = read_tsv("./data/ICPSR_25281/DS0001/25281-0001-Data.tsv")
m3p3 = read.table(file = "./data/ICPSR_37095/DS0001/37095-0001-Data.tsv", sep = '\t', header = TRUE)
mke1 = read_tsv("./data/MKE Data.tsv")
m2p4 = read_tsv("./data/ICPSR_29282/DS0001/29282-0001-Data.tsv") 
m2p1 = read_tsv("./data/ICPSR_04652/DS0001/04652-0001-Data.tsv")
m3p1 = read_tsv("./data/ICPSR_36346/DS0001/36346-0001-Data.tsv")
mke2 = read_tsv("./data/ICPSR_37120/DS0001/37120-0001-Data-REST.tsv")
```

```{r, echo=FALSE}
# added B1PA37, B1PA38A for smoking consistency checking
m2p1_selected = m2p1 %>% 
  select(M2ID, B1PAGE_M2, B1PRSEX, B1PF7A, B1PB1, B1PTSEI, B1PB19, B1PA6A, B1PA37, B1PA38A,
         B1PA39, B1SA11W, B1SA11Z,B1SA62A, B1SA62B, B1SA62C, B1SA62D, B1SA62E, B1SA62F, 
         B1SA62G, B1SA62H, B1SA62I, B1SA62J, B1SPWBA2, B1SPWBE2, B1SPWBG2, B1SPWBR2, B1SPWBU2, B1SPWBS2,
         B1SMASTE, B1SCONST, B1SCTRL, B1SESTEE, B1SINTER, B1SINDEP,
         B1SAGENC, B1SAGREE, B1SEXTRA, B1SNEURO, B1SCONS1)
m2p4_selected = m2p4 %>% 
  select(M2ID, B4QCT_EA, B4QCT_EN, B4QCT_MD, B4QCT_PA, B4QCT_PN, B4QCT_SA, B4HMETMW)
m2p3_selected = m2p3 %>% 
  select(M2ID, M2FAMNUM, B3TCOMPZ3, B3TEMZ3, B3TEFZ3, B3PIDATE_MO, B3PIDATE_YR)
m3p1_selected = m3p1 %>% 
  select(M2ID, C1PA6A, C1SA11Z, C1PB19)
m3p3_selected = m3p3 %>% 
  select(M2ID, M2FAMNUM, C3TCOMP, C3TEM, C3TEF, C3IDATE_MO, C3IDATE_YR, C1PRAGE)
```

## MIDUS 2
```{r}
# Data integration
m2_df = list(m2p3_selected, m2p1_selected, m2p4_selected) %>% reduce(full_join, by = "M2ID")

# Milwaukee sample family number filled in
m2_df = 
  m2_df %>% 
  mutate(M2FAMNUM = ifelse(is.na(M2FAMNUM), M2ID, M2FAMNUM))

# milwaukee sample information filled in
mke1_in_m2= intersect(m2_df$M2ID, mke1$M2ID)

# ethnicity: BACR7A = 2
# BACA36, BACA37 are counterpart of B1PA37, B1PA38A
mke1_to_add = 
  mke1 %>% 
  select(M2ID, BACRAGE, BACRSEX, BACB1, BACTSEI, BACB19, BACA6A, BACA36, BACA37, BACA39, BACAS11W,
         BACAS11Z, BACAS62A, BACAS62B, BACAS62C, BACAS62D, BACAS62E, BACAS62F, BACAS62G, BACAS62H,
         BACAS62I, BACAS62J, BASPWBA2, BASPWBE2, BASPWBG2, BASPWBR2, BASPWBU2, BASPWBS2,
         BASMASTE, BASCONST, BASCTRL, BASESTEE, BASINTER, BASINDEP, BASAGENC, BASAGREE,
         BASEXTRA, BASNEURO, BASCONS1) %>% 
  filter(M2ID %in% mke1_in_m2) %>% 
  mutate(BACR7A = 2) %>%  # added two more columns
  select(M2ID, BACRAGE, BACRSEX, BACR7A, everything())

# fill in data
for (i in 1:(length(mke1_to_add)-1)){
  for (j in mke1_to_add$M2ID){
    m2_df[m2_df$M2ID == j, i+7] = mke1_to_add[mke1_to_add$M2ID == j, i+1]
  }
}

# only keep those with CTQ numbers and Cognition Scores
m2_df = 
  m2_df %>% 
  filter(!(is.na(B4QCT_EA) & is.na(B4QCT_EN) & is.na(B4QCT_MD) & is.na(B4QCT_PA) & is.na(B4QCT_PN) & is.na(B4QCT_SA))) %>% 
  filter(!(is.na(B3TCOMPZ3) & is.na(B3TEMZ3) & is.na(B3TEFZ3)))

# Marital Status recoding (1-married; 0-others)
m2_df =
  m2_df %>% 
  mutate(B1PB19 = ifelse(B1PB19 == 1, 1, 0))

# resilience factors missing investigation
a = m2_df[,c(1,2,30:46)]

a[!complete.cases(a), ] %>% 
  filter(M2ID %in% mke1_in_m2) # missing data entries are all from the milwaukee sample
```

```{r}
# smoking inconsistency investigation
# B1PA39: now smoking cigarettes regularly. 1 - current, 2 - former, 9 - inapp (question skipped). 
#         backward skip: B1PA37 = NEVER (=96) or B1PA38A = 2, DK, refused (= 2, 9)
# B1PA37: age first smoking (age, 96 - never, 97 - dk) Never --> skip to 44
# B1PA38A: Ever smoked cigarettes regularly (1 - yes, 2 - no, 9 - inapp)

# non-smokers clear
m2_df %>% 
  select(M2ID, B1PA37, B1PA38A, B1PA39) %>% 
  filter(B1PA37 == 96) %>% 
  group_by(B1PA37, B1PA38A, B1PA39) %>% 
  summarize(n = n())

# B1PA37 = 97, may smoke before but forget the age
# B1PA38A = 1, B1PA39 = 2 --> former
# B1PA38A = 2, B1PA39 = 9 --> never
m2_df %>% 
  select(M2ID, B1PA37, B1PA38A, B1PA39) %>% 
  filter(B1PA37 == 97) %>% 
  group_by(B1PA37, B1PA38A, B1PA39) %>% 
  summarize(n = n())

# B1PA37 = age, smoked before
# be aware of those who smoked before but their B1PA39 = 9, 
# should categorize them as former instead of non-smokers (maybe?)
m2_df %>% 
  select(M2ID, B1PA37, B1PA38A, B1PA39) %>% 
  filter(!B1PA37 %in% c(96,97)) %>% 
  group_by(B1PA38A, B1PA39) %>% 
  summarize(n = n())


# Keep this variable as a dummy variable for now, may consider the B1PA40 (how many cig) later if found that this dummy variable is significant

# Data impute, if necessary
former_smokers = m2_df %>% 
  select(M2ID, B1PA37, B1PA38A, B1PA39) %>% 
  filter(!B1PA37 %in% c(96,97) & B1PA39 == 9) %>% 
  pull(M2ID)

m2_df[m2_df$M2ID %in% former_smokers, which(colnames(m2_df) == "B1PA39")] = 2
```


------- Done MIDUS 2 dataset integration and imputations -------
Stroke investigation is down below


## MIDUS 3
```{r}
m3_df = list(m3p3_selected, m3p1_selected) %>% reduce(left_join, by = "M2ID")

mke2_in_m3= intersect(m3_df$M2ID, mke2$M2ID)
```

All subjects whose don't have family numbers are from the Milwaukee sample (MKE2). Impute with their own ID.

```{r}
m3_df = 
  m3_df %>% 
  mutate(M2FAMNUM = ifelse(is.na(M2FAMNUM), M2ID, M2FAMNUM))
```

```{r}
# data imputation 
mke2_to_add = 
  mke2 %>% 
  select(M2ID, CACA6A, CACAS11Z, CACB19)

for (i in 1:(length(mke2_to_add)-1)){
  for (j in mke2_to_add$M2ID){
    m3_df[m3_df$M2ID == j, i+8] = mke2_to_add[mke2_to_add$M2ID == j, i+1]
  }
}

# no missing data in M3
m3_df %>% 
  select_if(function(x) any(is.na(x))) %>% 
  summarise_each(funs(sum(is.na(.))))
```

```{r}
# strokes
# noted that this stroke dataframe is smaller than the previous one: only 1049 entries. M3 missing 206 participants with no stroke data
stroke_df = merge(x = m2_df[, c("M2ID", "B1PA6A", "B1SA11Z")], y = m3_df[,c("M2ID", "C1PA6A", "C1SA11Z")], by = "M2ID", all.x=TRUE) %>% 
  filter(!(is.na(C1PA6A) & is.na(C1SA11Z))) %>% 
  mutate(B1PA6A = recode(B1PA6A, `2` = 0),
         C1PA6A = recode(C1PA6A, `2` = 0),
         B1SA11Z = recode(B1SA11Z, `2` = 0),
         C1SA11Z = recode(C1SA11Z, `2` = 0),
         D1PA6A = C1PA6A - B1PA6A, # D for delta
         D1SA11Z = C1SA11Z - B1SA11Z) 

# inconsistency check: M2.
# (12month history - history ever): -1 - have had stroke but not within 12 months
stroke_df %>% 
  mutate(inconsistency_checker = B1SA11Z - B1PA6A) %>% 
  group_by(inconsistency_checker, B1PA6A, B1SA11Z) %>% 
  summarize(size = n())

# copied from the previous file
# History: the changed: 0->1(1 target), 1->0(-1 invalid), 0->7(7 dk), 7->0(-7 invalid?), 7->1(-6 target), 1->7(6 invalid)
stroke_df %>% 
  filter(D1PA6A != 0) %>% 
  group_by(D1PA6A) %>% 
  summarize(n = n())

# inconsistency check: M3
# C1SA11Z: -1 as missing, 8 as refused, 0 as no, 1 as yes
# (12month history - history ever): -1 as "had one but not in the past 12 months", 1 as invalid
stroke_df %>% 
  filter(!C1SA11Z %in% c(-1,8)) %>%  # filter out the "unknown"
  mutate(inconsistency_checker = C1SA11Z - C1PA6A) %>% 
  group_by(inconsistency_checker, C1PA6A, C1SA11Z) %>% 
  summarize(size = n())

# just some further investigation, the inconsistent subjects are not from the Milwaukee sample
stroke_df %>% 
  filter(C1SA11Z == 1 & C1PA6A == 0) %>% 
  filter(M2ID %in% mke1_in_m2)

```
M2: The inconsistency checker has only 2 values: 0 and -1. Two possibilities for getting a 0: 1. had stroke before and/or had it within 12 months; 2. never have a stroke. For -1, the subject had a stroke some time before the questionnaire but it's not within 12 months. No inexplicable inconsistency here.

M3: The inconsistency checker has 4 values (5 combinations): -7, -1, 0, and 1. Two possibilities for getting a 0 as above."-7" indicates that the subject didn't know whether he/she had a stroke. "-1" indicates that the subject had a stroke some time before the questionnaire but it's not within 12 months. "1" is where the inconsistencies happened: the subject indicates that he/she had a stroke in the past 12 months but deny the fact that they have a stroke history. 

------- Done MIDUS 3 dataset integration and imputations -------

### Missing Data
```{r}
m2_df %>% 
  select_if(function(x) any(is.na(x))) %>% 
  summarise_each(funs(sum(is.na(.))))
missing_id = a[!complete.cases(a), ] %>% 
  filter(M2ID %in% mke1_in_m2) %>% 
  pull(M2ID)

m2_df %>% 
  filter(is.na(B1PPARTN)) %>% 
  filter(M2ID %in% missing_id)
# no cohabitation, no those 7 subjects
m2_df = m2_df %>% 
  filter(!(M2ID %in% missing_id))

write.csv(m2_df, "./data/m2_df.csv")
```





### Univariate Analysis
```{r}
# parameters setup 
theme1 = trellis.par.get()
theme1$plot.symbol$col = rgb(0.4556, 0.5444, 0, .3) 
theme1$plot.symbol$pch = 16
theme1$plot.line$col = rgb(0.8, 0, 0.2, 1)
theme1$plot.line$lwd = 2
theme1$strip.background$col = rgb(0.2611, 0.2124, 0.5265, .2)
trellis.par.set(theme1)
```

```{r fig.height=10, fig.width=10, out.width="90%"}
# some filtering first
m2_df_graph = m2_df %>% 
  drop_na() %>% # this step seems necessary, otherwise the dimensions are off
  filter(B4QCT_SA <= 25 & B1PTSEI <= 80.53 & B4HMETMW <= 26355 & B4QCT_EN <=25 & B4QCT_MD <= 3 & B4QCT_PN <= 21 &
           B1PB1 <= 12 & B4QCT_EA <= 25 & B3TCOMPZ3 < 4 & B3TEMZ3 < 4 & B3TEFZ3 < 4 & B1SPWBA2 < 50 & B1SPWBE2< 50 & B1SPWBG2<50 &
           B1SPWBR2 <50 & B1SPWBU2<50 & B1SPWBS2<50 & B1PF7A < 7 & B1PA6A < 3 & B1SA62A <3 & B1SA62B <3 &B1SA62C <3 
          & B1SA62D <3 & B1SA62E <3 & B1SA62F <3 & B1SA62G <3 & B1SA62H <3 & B1SA62I <3 & B1SA62J <3) 

# M2 continuous
m2_df_graph_cont = m2_df_graph %>% 
  select(-c(B1PRSEX, B1PF7A, B1PB19, B1PPARTN, B1PA6A, B1SA11W, B1SA11Z, B1SA62A, B1SA62B, 
            B1SA62C, B1SA62D, B1SA62E, B1SA62F, B1SA62G, B1SA62H, B1SA62I, B1SA62J, B3PIDATE_MO, B3PIDATE_YR, B1PA39))

# Cognition composite score
x_feature = model.matrix(`B3TCOMPZ3` ~., m2_df_graph_cont[3:15])[, -1]
y = m2_df_graph_cont$B3TCOMPZ3
featurePlot(x_feature, y, plot = "scatter", labels = c("", "Composite Scores"),
            type = c("p", "smooth"), layout = c(3,4))

# Episodic Memory
x_feature = model.matrix(`B3TEMZ3` ~., m2_df_graph_cont[3:15])[, -1]
y = m2_df_graph_cont$B3TEMZ3
featurePlot(x_feature, y, plot = "scatter", labels = c("", "Episodic Memory"),
            type = c("p", "smooth"), layout = c(3,4))

# Executive Function
x_feature = model.matrix(`B3TEFZ3` ~., m2_df_graph_cont[3:15])[, -1]
y = m2_df_graph_cont$B3TEFZ3
featurePlot(x_feature, y, plot = "scatter", labels = c("", "Executive Function"),
            type = c("p", "smooth"), layout = c(3,4))

# M2 categorical
m2_df_graph_cate = 
  m2_df[,!(colnames(m2_df) %in% colnames(m2_df_graph_cont[3:21]))] %>% 
  drop_na()

```

Covariates or confounding?

```{r fig.height=10, fig.width=10, out.width="90%"}
# graphs
# select variables that I thought are potential confounders
m2_df_cov = m2_df_graph %>% 
  select(B3TCOMPZ3, B3TEMZ3, B3TEFZ3, B1PAGE_M2, B1PRSEX, B1PF7A, B1PB1, B1PTSEI, B1PB19, B1PPARTN, B1PA39, B4HMETMW, B1SA11W, 
         B1SA62A, B1SA62B, B1SA62C, B1SA62D, B1SA62E, B1SA62F, 
         B1SA62G, B1SA62H, B1SA62I, B1SA62J, B1SPWBA2, B1SPWBE2, B1SPWBG2, B1SPWBR2, B1SPWBU2, B1SPWBS2, B4QCT_EA, B4QCT_EN,
         B4QCT_MD, B4QCT_PA, B4QCT_PN, B4QCT_SA)

m2_df_cov_cont = m2_df_cov[,!(colnames(m2_df_cov) %in% colnames(m2_df_graph_cate[3:22]))]

# B4QCT_EA
x_feature = model.matrix(`B4QCT_EA` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_EA
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_EA"),
            type = c("p", "smooth"), layout = c(3,7))

# B4QCT_EN
x_feature = model.matrix(`B4QCT_EN` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_EN
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_EN"),
            type = c("p", "smooth"), layout = c(3,7))

# B4QCT_MD
x_feature = model.matrix(`B4QCT_MD` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_MD
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_MD"),
            type = c("p", "smooth"), layout = c(3,7))

# B4QCT_PA
x_feature = model.matrix(`B4QCT_PA` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_PA
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_PA"),
            type = c("p", "smooth"), layout = c(3,7))

# B4QCT_PN
x_feature = model.matrix(`B4QCT_PN` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_PN
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_PN"),
            type = c("p", "smooth"), layout = c(3,7))

# B4QCT_SA
x_feature = model.matrix(`B4QCT_SA` ~., m2_df_cov_cont)[, -1]
y = m2_df_cov_cont$B4QCT_SA
featurePlot(x_feature, y, plot = "scatter", labels = c("", "B4QCT_SA"),
            type = c("p", "smooth"), layout = c(3,7))

```


Correlation Plot of independent variables in M2 dataset (i.e. `B3TCOMPZ3`,`B3TEMZ3`, `B3TEFZ3` are not included in the graph)
```{r fig.height=10, fig.width=10, out.width="100%"}
m2_df %>% 
  select(-c(M2ID, M2FAMNUM, B3TCOMPZ3, B3TEMZ3, B3TEFZ3)) %>% 
  ggcorr(label=TRUE, hjust = 0.9, layout.exp = 2, label_size = 3, label_round = 2)
```

High correlation between marital status and cohabitation, among the drug use variables (`B1SA62A - J`), among the CTQ score variables (`B4QCT_EA`, `B4QCT_EN`, `B4QCT_MD`, `B4QCT_PA`, `B4QCT_PN`, `B4QCT_SA`).




# Model building 
```{r}

```


